{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of unithood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains most parts of the analysis on unithood, the strength of association between components of concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils  # a python module in the same dir as the notebooks\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_NAME = 'acl'\n",
    "MODEL_NAME = CORPUS_NAME + 'arc'\n",
    "MODEL_SPEC = '_l7_min10'\n",
    "FREQ_THRESHOLD = 5\n",
    "\n",
    "INCLUDE_MESH_TERMS = True\n",
    "FILTER_STOP_WORDS = True\n",
    "FILTER_PUNCTUATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading n-gram model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ACL 2.0 corpus: 100%|██████████| 300/300 [00:00<00:00, 451.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(utils.ROOT)  # get to the root directory of the project\n",
    "\n",
    "from datautils import dataio, annotations as anno\n",
    "from stats import ngramcounting\n",
    "\n",
    "# load the corpus\n",
    "print('Loading n-gram model', flush=True)\n",
    "model = ngramcounting.NgramModel.load_model(MODEL_NAME, MODEL_SPEC)\n",
    "\n",
    "if CORPUS_NAME.lower() == 'pmc':\n",
    "    corpus = dataio.load_craft_corpus() + dataio.load_genia_corpus()\n",
    "else:\n",
    "    corpus = dataio.load_corpus(CORPUS_NAME.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0050435580009170105\n"
     ]
    }
   ],
   "source": [
    "ngram = tuple('markov chain model'.split())\n",
    "skipgram = (ngram[0], ngram[-1])\n",
    "\n",
    "print((model.prob(ngram, smoothing=0)\n",
    "      / model.prob(skipgram, smoothing=0))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7434"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.freq(skipgram, skipgrams=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: How strong is the association in regular concepts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all continuous concepts\n",
    "\n",
    "from stats import conceptstats\n",
    "cont_concepts = conceptstats.gold_standard_concepts(corpus, discontinuous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cont_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prob('probabilistic parsing model') / model.prob('probabilistic model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "concept_bigrams = {bigram for concept in cont_concepts for bigram in nltk.bigrams(concept)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INCLUDE_MESH_TERMS:\n",
    "    concept_bigrams.update(\n",
    "    {bigram for concept in dataio.load_mesh_terms()\n",
    "     for bigram in nltk.bigrams(concept)}\n",
    "    )\n",
    "if FILTER_STOP_WORDS:\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    concept_bigrams = {bg for bg in concept_bigrams\n",
    "                      if not (bg[0] in stopwords or bg[1] in stopwords)}\n",
    "if FILTER_PUNCTUATION:\n",
    "    import string\n",
    "    punct = string.punctuation\n",
    "    concept_bigrams = {bg for bg in concept_bigrams\n",
    "                      if not (bg[0] in punct or bg[1] in punct)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# now, loop over all bigrams in the n-gram model, measure their association\n",
    "# and note whether they occur in a concept or not\n",
    "\n",
    "data_dict = {'bigram': [], 'in_concept': [],  'pmi': [], 'll': [], 'tc': [], 'dice': [], 'combo': [], 'freq': []}\n",
    "\n",
    "for bigram_pattern, count in model.iterate(2, threshold=FREQ_THRESHOLD,\n",
    "                                           encoded_patterns=True):\n",
    "    \n",
    "    bigram = model.decode_pattern(bigram_pattern)\n",
    "    data_dict['bigram'].append(bigram)\n",
    "    \n",
    "    data_dict['freq'].append(count)\n",
    "    \n",
    "    word_a = bigram_pattern[0]\n",
    "    word_b = bigram_pattern[1]\n",
    "    contingency_table = model.contingency_table(word_a, word_b)\n",
    "    pmi = conceptstats.pointwise_mutual_information(contingency_table)\n",
    "    data_dict['pmi'].append(pmi)\n",
    "    ll = conceptstats.log_likelihood_ratio(contingency_table)\n",
    "    data_dict['ll'].append(ll)\n",
    "    tc = conceptstats.term_coherence(bigram, model)\n",
    "    data_dict['tc'].append(tc)\n",
    "    dice = conceptstats.term_coherence(bigram, model) / math.log10(count)\n",
    "    data_dict['dice'].append(dice)\n",
    "    combo = pmi + math.log10(count) * 2\n",
    "    data_dict['combo'].append(combo)\n",
    "    \n",
    "    data_dict['in_concept'].append(bigram in concept_bigrams)\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of bigram types:\n",
    "print('Outside:', len(data[data['in_concept'] == False]))\n",
    "print('Inside:', len(data[data['in_concept'] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x='in_concept', y='pmi', data=data, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utils.prepare_comparable_latex_boxplots('in_concept', 'pmi', data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['in_concept'] == True)].sort_values('combo', ascending=False).head(10)\n",
    "#  & (data['pmi'] < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "csv_string = data[(data['in_concept'] == False)  & (data['pmi'] < 4)].sort_values('pmi', ascending=False).tail(10).to_csv(sep='&')\n",
    "csv_string = csv_string.replace('&True', '')\n",
    "csv_string = csv_string.replace(\"('\", '')\n",
    "csv_string = csv_string.replace(\"')\", '')\n",
    "csv_string = csv_string.replace(\"', '\", ' ')\n",
    "csv_string = csv_string.replace('\\n', '\\\\\\\\\\n')\n",
    "csv_string = re.sub('\\n\\d+&', '\\n', csv_string)\n",
    "csv_string = csv_string.replace('&', '\\t& ')\n",
    "print(csv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['in_concept'] == True)].sort_values('ll', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can perform t-tests etc.\n",
    "import pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_result = pingouin.ttest(list(data[data['in_concept'] == True]['pmi']),\n",
    "               list(data[data['in_concept'] == False]['pmi']),\n",
    "               correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pingouin.compute_effsize_from_t(t_test_result['T'][0],\n",
    "                                nx=len(list(data[data['in_concept'] == True]['pmi'])),\n",
    "                                ny=len(list(data[data['in_concept'] == False]['pmi'])),\n",
    "                                eftype='cles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pingouin.mwu(list(data[data['in_concept'] == True]['ll']),\n",
    "             list(data[data['in_concept'] == False]['ll']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('dice', 'tc', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('tc')[(data['pmi'] > 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptstats.ngram_pmi('training', 'data', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: concept bigrams _do_ have higher association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cont_concepts:\n",
    "    if len(c) == 4 and 'and' in c:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: How does it look for bigrams in DC's?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_concepts = conceptstats.gold_standard_concepts(corpus, continuous=False,\n",
    "                                                    discontinuous=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra dc's: skipgrams from CC's which are also CC's and hence a valid DC\n",
    "if False:\n",
    "    extra_dcs = set()\n",
    "    for concept in cont_concepts:\n",
    "        count = 0\n",
    "        for sg in set(ngramcounting.make_skipgrams(concept)).difference(\n",
    "            ngramcounting.make_ngrams(concept)):\n",
    "            if sg in cont_concepts:\n",
    "                print(concept, '-->', sg)\n",
    "                extra_dcs.add(sg)\n",
    "    disc_concepts.update(extra_dcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_bigrams = {bigram for concept in disc_concepts for bigram in nltk.bigrams(concept)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FILTER_STOP_WORDS:\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    dc_bigrams = {bg for bg in dc_bigrams\n",
    "                  if not (bg[0] in stopwords or bg[1] in stopwords)}\n",
    "if FILTER_PUNCTUATION:\n",
    "    import string\n",
    "    punct = string.punctuation\n",
    "    dc_bigrams = {bg for bg in dc_bigrams\n",
    "                  if not (bg[0] in punct or bg[1] in punct)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# now, loop over all bigrams in the n-gram model, measure their association\n",
    "# and note whether they occur in a concept or not\n",
    "\n",
    "data_dict = {'bigram': [], 'type': [],  'pmi': [], 'll': [], 'tc': [], 'dice': [], 'combo': [], 'freq': []}\n",
    "\n",
    "for bigram_pattern, count in model.iterate(2, threshold=FREQ_THRESHOLD,\n",
    "                                           encoded_patterns=True):\n",
    "    \n",
    "    bigram = model.decode_pattern(bigram_pattern)\n",
    "    \n",
    "    if bigram in concept_bigrams:\n",
    "        if bigram in dc_bigrams:\n",
    "            bigram_type = 'both'\n",
    "        else:\n",
    "            bigram_type = 'only_CC'\n",
    "    elif bigram in dc_bigrams:\n",
    "        #continue\n",
    "        bigram_type = 'only_DC'\n",
    "    else:\n",
    "        bigram_type = 'neither'\n",
    "    data_dict['type'].append(bigram_type)\n",
    "    \n",
    "    data_dict['bigram'].append(bigram)\n",
    "    \n",
    "    data_dict['freq'].append(math.log10(count))\n",
    "    \n",
    "    word_a = bigram_pattern[0]\n",
    "    word_b = bigram_pattern[1]\n",
    "    contingency_table = model.contingency_table(word_a, word_b)\n",
    "    pmi = conceptstats.pointwise_mutual_information(contingency_table)\n",
    "    data_dict['pmi'].append(pmi)\n",
    "    ll = conceptstats.log_likelihood_ratio(contingency_table)\n",
    "    data_dict['ll'].append(ll)\n",
    "    tc = conceptstats.term_coherence(bigram, model)\n",
    "    data_dict['tc'].append(tc)\n",
    "    dice = tc / math.log10(count)\n",
    "    data_dict['dice'].append(dice)\n",
    "    combo = pmi + math.log10(count)\n",
    "    data_dict['combo'].append(combo)\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='type', y='freq', data=data, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utils.prepare_comparable_latex_boxplots('type', 'freq', data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='pmi', y='freq', hue='type', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pingouin.homoscedasticity(data, 'pmi', 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pingouin.qqplot(list(data[data['type'] == 'only_CC']['pmi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pingouin.welch_anova(data, 'dice', 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise = pingouin.pairwise_tukey(data, 'pmi', 'type', effsize='CLES')#.to_csv(sep='&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_string = pairwise.drop(columns=['mean(A)', 'mean(B)', 'se', 'tail', 'diff']).to_csv(sep='&')\n",
    "csv_string = csv_string.replace('\\n', '\\\\\\\\\\n')\n",
    "csv_string = re.sub('\\n\\d+&', '\\n', csv_string)\n",
    "csv_string = csv_string.replace('&', '\\t& ')\n",
    "print(csv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pingouin.compute_effsize_from_t(86.845, nx=len(list(data[data['type'] == 'neither']['pmi'])),\n",
    "                                ny=len(list(data[data['type'] == 'only_CC']['pmi'])), eftype='cles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['type'] == 'both'].sort_values('pmi', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{bg for bg in data[data['type'] == 'only_CC']['bigram'] if bg[0] == 'bone'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='type', y='tc', data=data, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utils.prepare_comparable_latex_boxplots('type', 'll', data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, notice that\n",
    "len(data[data['type'] == 'only_DC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared to e.g.\n",
    "len(data[data['type'] == 'both'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: What is the association across the gap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "gap_bigrams = defaultdict(list)\n",
    "cont_bigrams = defaultdict(list)\n",
    "dc_sample = {dc for doc in corpus for dc in doc.get_annotations(anno.DiscontinuousConcept)}\n",
    "for dc in dc_sample:\n",
    "    tokens = dc.get_tokens()\n",
    "    norm_concept = dc.normalized_concept()\n",
    "    spanned_tokens = dc.get_spanned_tokens()\n",
    "    non_dc_tokens = set(spanned_tokens).difference(tokens)\n",
    "    for t in non_dc_tokens:\n",
    "        if t.mapped_pos() == 'c':\n",
    "            cc = t\n",
    "            break\n",
    "    for i in range(len(tokens) - 1):\n",
    "        t1, t2 = tokens[i], tokens[i+1]\n",
    "        bigram = norm_concept[i:i + 2]\n",
    "        if t2.span[0] - t1.span[-1] > 2:\n",
    "            gap_bigrams[bigram].append(dc)\n",
    "\n",
    "        else:\n",
    "            cont_bigrams[bigram].append(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'bigram': [], 'freq': [], 'pmi': [], 'll': [], 'tc': [], 'combo': [], 'type': [], 'in_concept': []}\n",
    "\n",
    "all_bigrams = set.union(set(gap_bigrams.keys()), set(cont_bigrams.keys()))\n",
    "for bigram in all_bigrams:\n",
    "    # skip if not frequent enough\n",
    "    if model.freq(bigram) < FREQ_THRESHOLD:\n",
    "        continue\n",
    "\n",
    "    data_dict['bigram'].append(bigram)\n",
    "    count = model.freq(bigram)\n",
    "    data_dict['freq'].append(math.log10(count))\n",
    "\n",
    "    contingency_table = model.contingency_table(bigram[0], bigram[1], smoothing=1)\n",
    "    pmi = conceptstats.pointwise_mutual_information(contingency_table)\n",
    "    data_dict['pmi'].append(pmi)\n",
    "    ll = conceptstats.log_likelihood_ratio(contingency_table)\n",
    "    data_dict['ll'].append(ll)\n",
    "    tc = conceptstats.term_coherence(bigram, model)\n",
    "    data_dict['tc'].append(tc)\n",
    "    combo = pmi + math.log10(count)\n",
    "    data_dict['combo'].append(combo)\n",
    "\n",
    "    # how it occurs\n",
    "    if bigram in gap_bigrams:\n",
    "        if bigram in cont_bigrams: \n",
    "            type_ = 'both'\n",
    "        else:\n",
    "            type_ = 'only_gap'\n",
    "    elif bigram in cont_bigrams:\n",
    "        type_ = 'only_cont'\n",
    "    else:\n",
    "        type_ = 'weird'\n",
    "\n",
    "    data_dict['type'].append(type_)\n",
    "    \n",
    "    data_dict['in_concept'].append(bigram in concept_bigrams)\n",
    "\n",
    "data = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "\n",
    "That a bigram occurs as `only_gap` means that it occurs only in gap position for DC's. However, those bigrams can just as well occur in CC's as well, thereby getting a high association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='type', y='freq', data=data, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utils.prepare_comparable_latex_boxplots('type', 'freq', data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='pmi', y='freq', hue='type', data=data)\n",
    "sns.lineplot(x=[-2, 10], y=[1.7, 1.7])\n",
    "sns.lineplot(x=[1.5, 1.5], y=[0, 5])\n",
    "sns.lineplot(x=[-1, 0, 1], y=[2 ,1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.log10(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['combo'] < 1]) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utils.prepare_comparable_latex_boxplots('type', 'pmi', data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['type'] == 'only_gap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pingouin.homoscedasticity(data, 'combo', 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pingouin.welch_anova(data, 'combo', 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise = pingouin.pairwise_tukey(data, 'pmi', 'type', effsize='cles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_string = pairwise.drop(columns=['mean(A)', 'mean(B)', 'se', 'tail', 'diff']).to_csv(sep='&')\n",
    "csv_string = csv_string.replace('\\n', '\\\\\\\\\\n')\n",
    "csv_string = re.sub('\\n\\d+&', '\\n', csv_string)\n",
    "csv_string = csv_string.replace('&', '\\t& ')\n",
    "print(csv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='type', y='ll', data=data, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='type', y='tc', data=data, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='type', y='freq', data=data, showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: What is the full-term unithood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_concepts = disc_concepts.union(cont_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'concept': [], 'type': [],  'pmi_nl': [], 'tc': [], 'freq': [], 'len': []}\n",
    "\n",
    "for concept in all_concepts:\n",
    "    \n",
    "    if model[concept] < FREQ_THRESHOLD:\n",
    "        continue\n",
    "    \n",
    "    data_dict['concept'].append(concept)\n",
    "    \n",
    "    data_dict['freq'].append(model[concept])\n",
    "    \n",
    "    if concept in disc_concepts:\n",
    "        if concept in cont_concepts:\n",
    "            concept_type = 'both'\n",
    "        else:\n",
    "            concept_type = 'only_DC'\n",
    "    else:\n",
    "        concept_type = 'only_CC'\n",
    "    data_dict['type'].append(concept_type)\n",
    "    \n",
    "    data_dict['pmi_nl'].append(conceptstats.length_normalized_pmi(concept, model))\n",
    "    data_dict['tc'].append(conceptstats.term_coherence(concept, model))\n",
    "    \n",
    "    data_dict['len'].append(len(concept))\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('tc', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[(data['pmi_nl'] < 2) & (data['len'] == 2)]) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='type', y='freq', data=data, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'ngram': [], 'freq': [], 'type': [], 'tc': [], 'pmi': [], 'pmi_nl': [], 'len': []}\n",
    "\n",
    "for n in range(2, 11):\n",
    "    for ngram, count in model.iterate(n, FREQ_THRESHOLD):\n",
    "        \n",
    "        ngram = tuple(ngram.split())\n",
    "\n",
    "        data_dict['ngram'].append(ngram)\n",
    "\n",
    "        data_dict['freq'].append(model[ngram])\n",
    "\n",
    "        if ngram in disc_concepts:\n",
    "            if ngram in cont_concepts:\n",
    "                ngram_type = 'both'\n",
    "            else:\n",
    "                ngram_type = 'only_DC'\n",
    "        elif ngram in cont_concepts:\n",
    "            ngram_type = 'only_CC'\n",
    "        else:\n",
    "            ngram_type = 'neither'\n",
    "            \n",
    "        data_dict['type'].append(ngram_type)\n",
    "\n",
    "        data_dict['pmi'].append(conceptstats.length_normalized_pmi(ngram, model) * (len(ngram) - 1))\n",
    "        data_dict['pmi_nl'].append(conceptstats.length_normalized_pmi(ngram, model))\n",
    "        data_dict['tc'].append(conceptstats.term_coherence(ngram, model))\n",
    "\n",
    "        data_dict['len'].append(len(ngram))\n",
    "        \n",
    "data = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='type', y='pmi_nl', data=data, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utils.prepare_comparable_latex_boxplots('len', 'pmi_nl', data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
