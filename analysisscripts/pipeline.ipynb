{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "os.chdir(utils.ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ACL 2.0 corpus:  18%|█▊        | 55/300 [00:00<00:00, 414.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: LOAD GOLD DOCUMENTS AND CONCEPTS\n",
      "Loading gold docs: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ACL 2.0 corpus: 100%|██████████| 300/300 [00:00<00:00, 454.58it/s]\n",
      "Removing unigram Concepts: 100%|██████████| 300/300 [00:00<00:00, 1373.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving gold standard concepts ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading ACL 2.0 corpus: 100%|██████████| 300/300 [00:00<00:00, 4032.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 concepts not bounded at tokens boundaries and filtered out 0 with the POS-tag filter: None\n",
      "STEP 2: Run pre-processing and concept extraction pipeline\n",
      "--- Running pre-processing pipeline ---\n",
      "Opening CoreNLP annotator server. It may still be running after termination if shut-down is not stated explicitly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Annotating batch: 100%|██████████| 300/300 [00:01<00:00, 159.29it/s]\n",
      "Creating raw text corpus file:  16%|█▋        | 49/300 [00:00<00:00, 489.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoreNLP server shut down successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating raw text corpus file: 100%|██████████| 300/300 [00:00<00:00, 444.70it/s]\n",
      "Extracting candidates:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making colibri class file ...\n",
      "Encoding corpus ...\n",
      "--- Running concept extraction pipeline ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting candidates: 100%|██████████| 300/300 [00:02<00:00, 145.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 6437 continuous candidates and 1314 discontinuous candidates.\n",
      "Scoring, ranking and filtering concepts\n",
      "Calculating C-values\n",
      "Calculating Rectified Frequencies\n",
      "Calculating TF-IDF values\n",
      "Calculating Glossex values\n",
      "Loading reference model for the first time.\n",
      "Calculating length normalized PMI values\n",
      "Calculating Term Coherence values\n",
      "Calculating votes between rankers\n",
      "Loading MeSH terms ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning documents: 100%|██████████| 300/300 [00:00<00:00, 341555.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 3: EVALUATE\n",
      "THRESHOLD = 1\n",
      "Summary of CorpusReport for Concept\n",
      "# extracted concepts: 1593\n",
      "Precision: 0.525   (highest: 1.000, lowest: 0.000)\n",
      "Recall:    0.278   (highest: 1.000, lowest: 0.000)\n",
      "Error analysis of CorpusReport for Concept\n",
      "516 (68.25%) FP's occur elsewhere as a gold standard concept.\n",
      "75 (9.92%) FP's were verified in ontology source(s).\n",
      "550 (72.75%) FP's were accounted for in this analysis.\n",
      "Corrected precision: 0.871\n",
      "141 (6.48%) FN's are above max n.\n",
      "44 (2.02%) FN's cannot be captured by the used POS-tag filter.\n",
      "1972 (90.67%) FN's occur less often than the frequency threshold.\n",
      "1990 (91.49%) FN's were accounted for in this analysis.\n",
      "Corrected recall: 0.819\n",
      "\n",
      "Summary of CorpusReport for DiscontinuousConcept\n",
      "# extracted concepts: 85\n",
      "Precision: 0.000   (highest: 0.000, lowest: 0.000)\n",
      "Recall:    0.000   (highest: 0.000, lowest: 0.000)\n",
      "Error analysis of CorpusReport for DiscontinuousConcept\n",
      "70 (82.35%) FP's occur elsewhere as a gold standard concept.\n",
      "12 (14.12%) FP's were verified in ontology source(s).\n",
      "73 (85.88%) FP's were accounted for in this analysis.\n",
      "Corrected precision: 0.859\n",
      "\n",
      "Summary of TypesReport\n",
      "# types      525\n",
      "Precision:   0.77\n",
      "Recall:      0.163\n",
      "F1-measure:  0.269\n",
      "Precision at k:\n",
      "\tP@100    0.91\n",
      "\tP@200    0.9\n",
      "\tP@500    0.782\n",
      "\tP@525    0.77\n",
      "Error analysis of TypesReport\n",
      "1 (0.83%) FP's were verified.\n",
      "1 (0.83%) FP's were accounted for in this analysis.\n",
      "Corrected precision: 0.771\n",
      "133 (6.41%) FN's are above max n.\n",
      "1985 (95.66%) FN's occur less often than the frequency threshold.\n",
      "1989 (95.86%) FN's were accounted for in this analysis.\n",
      "Corrected recall: 0.824\n"
     ]
    }
   ],
   "source": [
    "from pipeline import runpipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(\n",
    "    {'freq_threshold': list(range(4, 5, 2)),\n",
    "     'all_prec': [r.precision() for r in runpipeline.all_corpus_reports],\n",
    "     'all_corr_prec': [r.corrected_precision() for r in runpipeline.all_corpus_reports],\n",
    "     'all_recall': [r.recall() for r in runpipeline.all_corpus_reports],\n",
    "     'all_corr_recall': [r.corrected_recall() for r in runpipeline.all_corpus_reports],\n",
    "     'all_n_concepts': [len(r.predicted) for r in runpipeline.all_corpus_reports],\n",
    "     'dc_prec': [r.precision() for r in runpipeline.all_dc_reports],\n",
    "     'dc_corr_prec': [r.corrected_precision() for r in runpipeline.all_dc_reports],\n",
    "     'dc_recall': [r.recall() for r in runpipeline.all_dc_reports],\n",
    "     'dc_corr_recall': [r.corrected_recall() for r in runpipeline.all_dc_reports],\n",
    "     'dc_n_concepts': [len(r.predicted) for r in runpipeline.all_dc_reports],\n",
    "     'types_prec': [r.precision() for r in runpipeline.all_types_reports],\n",
    "     'types_corr_prec': [r.corrected_precision() for r in runpipeline.all_types_reports],\n",
    "     'types_recall': [r.recall() for r in runpipeline.all_types_reports],\n",
    "     'types_corr_recall': [r.corrected_recall() for r in runpipeline.all_types_reports],\n",
    "     'types_n_concepts': [len(r.predicted) for r in runpipeline.all_types_reports]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc081ed01d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data['all_n_concepts'], data['all_corr_prec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'freq_threshold': 2, 'c_value_threshold': 2, 'max_n': 5, 'skipgrams': False, 'bridge_strength_threshold': 1, 'freq_factor': 1, 'coord_dcs': True, 'hypernym_dcs': True, 'consider_dcs_in_ranking': False, 'extraction_filter': 'simple'}\n"
     ]
    }
   ],
   "source": [
    "print(runpipeline.configs.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the results? \n"
     ]
    }
   ],
   "source": [
    "if input('Save the results? ') == 'y':\n",
    "    save_dir = '/home/kasper/Dropbox/Masters thesis/pipeline-results/'\n",
    "    name = input('File name: ')\n",
    "    data.to_csv(save_dir + name + '.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_ranks = {\n",
    "    c: runpipeline.metrics[c.normalized_concept()][runpipeline.cm.Metrics.VOTER]\n",
    "    if runpipeline.cm.Metrics.VOTER in runpipeline.metrics[c.normalized_concept()]\n",
    "    else 0 for c in runpipeline.all_dc_reports[0].predicted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stats import conceptstats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech recognition\ttheme is the use of \u001b[46m\u001b[30mspeech\u001b[0m and text-image \u001b[46m\u001b[30mrecognition\u001b[0m to retrieve arbitra\t0.2964938220586285\t9.921950477333773\n",
      "dialogue system\ton, developed for a \u001b[46m\u001b[30mdialogue\u001b[0m translation \u001b[46m\u001b[30msystem\u001b[0m. The system utilize\t0.2614910156366174\t6.8788057145009365\n",
      "word vector\ty of distributional \u001b[46m\u001b[30mword\u001b[0m feature \u001b[46m\u001b[30mvectors\u001b[0m and its impact on w\t0.22206702380748333\t3.2628968373665455\n",
      "training data\trocess of obtaining \u001b[46m\u001b[30mtraining\u001b[0m and test \u001b[46m\u001b[30mdata\u001b[0m for subcategorizati\t0.15421451956650267\t9.172128774263845\n",
      "training data\td match between the \u001b[46m\u001b[30mtraining\u001b[0m and test \u001b[46m\u001b[30mdata\u001b[0m with respect to top\t0.15421451956650267\t9.172128774263845\n",
      "dialog system\toach for creating a \u001b[46m\u001b[30mdialog\u001b[0m management \u001b[46m\u001b[30msystem\u001b[0m based on a Construc\t0.14142014890031696\t7.01031896747316\n",
      "translation system\tal performance of a \u001b[46m\u001b[30mtranslation\u001b[0m memory \u001b[46m\u001b[30msystem\u001b[0m. We take a selectio\t0.10472307272372758\t6.651197622742385\n",
      "natural language system\tincorporated into a \u001b[46m\u001b[30mnatural language\u001b[0m generation \u001b[46m\u001b[30msystem\u001b[0m.\t0.10441124897068303\t5.063651267080507\n",
      "natural language system\tount of a prototype \u001b[46m\u001b[30mnatural language\u001b[0m question answering \u001b[46m\u001b[30msystem\u001b[0m, called Chat-80. Ch\t0.10441124897068303\t5.063651267080507\n",
      "natural language system\turrent experimental \u001b[46m\u001b[30mnatural language\u001b[0m processing \u001b[46m\u001b[30msystems\u001b[0m: coping with an inc\t0.10441124897068303\t5.063651267080507\n",
      "language system\tated into a natural \u001b[46m\u001b[30mlanguage\u001b[0m generation \u001b[46m\u001b[30msystem\u001b[0m.\t0.09121758036795137\t5.063651267080507\n",
      "language system\txperimental natural \u001b[46m\u001b[30mlanguage\u001b[0m processing \u001b[46m\u001b[30msystems\u001b[0m: coping with an inc\t0.09121758036795137\t5.063651267080507\n",
      "language system\tresentation used by \u001b[46m\u001b[30mlanguage\u001b[0m processing \u001b[46m\u001b[30msystems\u001b[0m is not geared to le\t0.09121758036795137\t5.063651267080507\n",
      "language system\ta prototype natural \u001b[46m\u001b[30mlanguage\u001b[0m question answering \u001b[46m\u001b[30msystem\u001b[0m, called Chat-80. Ch\t0.09121758036795137\t5.063651267080507\n",
      "language system\tus adopts the Child \u001b[46m\u001b[30mLanguage\u001b[0m Data Exchange \u001b[46m\u001b[30mSystem\u001b[0m (CHILDES). The size\t0.09121758036795137\t5.063651267080507\n",
      "robust parsing\t. The system uses a \u001b[46m\u001b[30mrobust\u001b[0m island-based \u001b[46m\u001b[30mparsing\u001b[0m method controlled b\t0.08137210803563871\t7.264878640451884\n",
      "robust parsing\tsystem include: (i) \u001b[46m\u001b[30mRobust\u001b[0m efficient \u001b[46m\u001b[30mparsing\u001b[0m of Korean (a verb f\t0.08137210803563871\t7.264878640451884\n",
      "robust parsing\tf the best existing \u001b[46m\u001b[30mrobust\u001b[0m probabilistic \u001b[46m\u001b[30mparsing\u001b[0m models, which we ca\t0.08137210803563871\t7.264878640451884\n",
      "% accuracy\tm achieves around 97\u001b[46m\u001b[30m%\u001b[0m exact match \u001b[46m\u001b[30maccuracy\u001b[0m on a test corpus co\t0.06020052915215037\t6.2045075862837535\n",
      "syntactic analysis\tpled techniques for \u001b[46m\u001b[30msyntactic\u001b[0m and pragmatic \u001b[46m\u001b[30manalysis\u001b[0m can be bolstered wi\t0.058847995575303166\t7.298624878340613\n",
      "trigram model\tel and a word-based \u001b[46m\u001b[30mtrigram\u001b[0m language \u001b[46m\u001b[30mmodel\u001b[0m. During training, t\t0.05815634435798189\t7.49952898826619\n",
      "trigram model\the algorithm uses a \u001b[46m\u001b[30mtrigram\u001b[0m language \u001b[46m\u001b[30mmodel\u001b[0m to determine the mo\t0.05815634435798189\t7.49952898826619\n",
      "context-free grammar\tines a conventional \u001b[46m\u001b[30mcontext-free\u001b[0m morphological \u001b[46m\u001b[30mgrammar\u001b[0m to filter out ungra\t0.056350723099966346\t9.208184586147626\n",
      "context-free grammar\td towards utilizing \u001b[46m\u001b[30mcontext-free\u001b[0m phrase-structure \u001b[46m\u001b[30mgrammar\u001b[0m as a backbone, e.g.\t0.056350723099966346\t9.208184586147626\n",
      "sense-tagged data\ttomatically acquire \u001b[46m\u001b[30msense-tagged\u001b[0m training \u001b[46m\u001b[30mdata\u001b[0m from English-Chines\t0.05595849041468562\t6.479023253856173\n",
      "% improvement\tlgorithm show a 35.0\u001b[46m\u001b[30m%\u001b[0m relative \u001b[46m\u001b[30mimprovement\u001b[0m over our baseline s\t0.05303674800609725\t5.16953479702593\n",
      "statistical model\tlinear models allow \u001b[46m\u001b[30mstatistical\u001b[0m alignment \u001b[46m\u001b[30mmodels\u001b[0m to be easily extend\t0.04792346349926869\t6.853855529987622\n",
      "statistical model\tate Model (FSM) and \u001b[46m\u001b[30mStatistical\u001b[0m Learning \u001b[46m\u001b[30mModel\u001b[0m (SLM). FSM provides\t0.04792346349926869\t6.853855529987622\n",
      "statistical model\t we first train two \u001b[46m\u001b[30mstatistical\u001b[0m word alignment \u001b[46m\u001b[30mmodels\u001b[0m with the large-scal\t0.04792346349926869\t6.853855529987622\n",
      "statistical model\tpora is proposed. A \u001b[46m\u001b[30mstatistical\u001b[0m translation \u001b[46m\u001b[30mmodel\u001b[0m is also presented t\t0.04792346349926869\t6.853855529987622\n",
      "log-linear model\triterion to train a \u001b[46m\u001b[30mlog-linear\u001b[0m block bigram \u001b[46m\u001b[30mmodel\u001b[0m which uses real-val\t0.04755033572258681\t8.392655022200977\n",
      "unsupervised algorithm\tases. We present an \u001b[46m\u001b[30munsupervised\u001b[0m learning \u001b[46m\u001b[30malgorithm\u001b[0m for identification \t0.047206463429275626\t4.98798368522707\n",
      "discourse structure\there Underspecified \u001b[46m\u001b[30mDiscourse\u001b[0m Representation \u001b[46m\u001b[30mStructures\u001b[0m (UDRSs). The method\t0.04313489284506635\t7.401429138039135\n",
      "test data\tle of plausibility. \u001b[46m\u001b[30mTest\u001b[0m performance \u001b[46m\u001b[30mdata\u001b[0m will show that a PC\t0.03819845195251784\t7.597418725411044\n",
      "bilingual corpus\tk can be done using \u001b[46m\u001b[30mbilingual\u001b[0m parallel \u001b[46m\u001b[30mcorpora\u001b[0m, a much more common\t0.03646623542028608\t7.828729989104257\n",
      "bilingual corpus\tes extracted from a \u001b[46m\u001b[30mbilingual\u001b[0m parallel \u001b[46m\u001b[30mcorpus\u001b[0m to be ranked using \t0.03646623542028608\t7.828729989104257\n",
      "large corpus\t polysemous word; a \u001b[46m\u001b[30mlarge\u001b[0m textual \u001b[46m\u001b[30mcorpus\u001b[0m will then be search\t0.033059092950025744\t7.783630296898419\n",
      "large corpus\t parallel data from \u001b[46m\u001b[30mlarge\u001b[0m Chinese, Arabic, and English non-parallel newspaper \u001b[46m\u001b[30mcorpora\u001b[0m. We evaluate the qu\t0.033059092950025744\t7.783630296898419\n",
      "large corpus\trd segmenter from a \u001b[46m\u001b[30mlarge\u001b[0m unsegmented Arabic \u001b[46m\u001b[30mcorpus\u001b[0m. The algorithm uses\t0.033059092950025744\t7.783630296898419\n",
      "large corpus\ts) and exploiting a \u001b[46m\u001b[30mlarge\u001b[0m non-parallel \u001b[46m\u001b[30mcorpus\u001b[0m. Thus, our method c\t0.033059092950025744\t7.783630296898419\n",
      "csr corpus\t development of the \u001b[46m\u001b[30mCSR\u001b[0m pilot \u001b[46m\u001b[30mcorpus\u001b[0m, and examines the d\t0.030847144785643904\t6.8318393777387305\n",
      "ibm model\tficantly outperform \u001b[46m\u001b[30mIBM\u001b[0m translation \u001b[46m\u001b[30mmodels\u001b[0m.\t0.029483208276402533\t7.395249477005182\n",
      "syntactic information\tcorporates lexical, \u001b[46m\u001b[30msyntactic\u001b[0m, semantic, and structural \u001b[46m\u001b[30minformation\u001b[0m from the parse tree\t0.02297428425389397\t6.114934330389672\n",
      "unlexicalized parser\trable to that of an \u001b[46m\u001b[30munlexicalized\u001b[0m PCFG \u001b[46m\u001b[30mparser\u001b[0m created using exten\t0.020159101693621166\t5.979278177282441\n",
      "translation quality\t IBM models in both \u001b[46m\u001b[30mtranslation\u001b[0m speed and \u001b[46m\u001b[30mquality\u001b[0m.\t0.0198342727529909\t7.578661687946433\n",
      "markov model\tds using m-th order \u001b[46m\u001b[30mMarkov\u001b[0m chain \u001b[46m\u001b[30mmodel\u001b[0m for Japanese kanji-\t0.01914735177629059\t9.017611039578453\n",
      "source language sentence\tfrom parse-trees of \u001b[46m\u001b[30msource\u001b[0m and target \u001b[46m\u001b[30mlanguage sentences\u001b[0m. We report the perf\t0.018572812730594877\t6.849652229061629\n",
      "statistical approach\tds, like most other \u001b[46m\u001b[30mstatistical\u001b[0m NLP \u001b[46m\u001b[30mapproaches\u001b[0m, suffer from the pr\t0.017456276153116936\t7.007250377354874\n",
      "segmented corpus\tby a small manually \u001b[46m\u001b[30msegmented\u001b[0m Arabic \u001b[46m\u001b[30mcorpus\u001b[0m and uses it to boot\t0.015895696844996778\t5.567014147559855\n",
      "generative model\tWe describe a \u001b[46m\u001b[30mgenerative\u001b[0m probabilistic \u001b[46m\u001b[30mmodel\u001b[0m of natural language\t0.015076660087388963\t7.100553419625591\n",
      "generative model\this paper defines a \u001b[46m\u001b[30mgenerative\u001b[0m probabilistic \u001b[46m\u001b[30mmodel\u001b[0m of parse trees, whi\t0.015076660087388963\t7.100553419625591\n",
      "automatic evaluation\tg the NIST and Bleu \u001b[46m\u001b[30mautomatic\u001b[0m MT \u001b[46m\u001b[30mevaluation\u001b[0m software. The resul\t0.013901692436455684\t7.46128799317364\n",
      "automatic evaluation\telation between the \u001b[46m\u001b[30mautomatic\u001b[0m parse-based \u001b[46m\u001b[30mevaluation\u001b[0m and a manual evalua\t0.013901692436455684\t7.46128799317364\n",
      "automatic evaluation\t novel and likewise \u001b[46m\u001b[30mautomatic\u001b[0m and unsupervised \u001b[46m\u001b[30mevaluation\u001b[0m method inspired by \t0.013901692436455684\t7.46128799317364\n",
      "probabilistic model\test existing robust \u001b[46m\u001b[30mprobabilistic\u001b[0m parsing \u001b[46m\u001b[30mmodels\u001b[0m, which we call P-CF\t0.013622221045500406\t7.783257144914728\n",
      "probabilistic model\tems associated with \u001b[46m\u001b[30mprobabilistic\u001b[0m translation \u001b[46m\u001b[30mmodels\u001b[0m that have recently \t0.013622221045500406\t7.783257144914728\n",
      "unsupervised method\tewise automatic and \u001b[46m\u001b[30munsupervised\u001b[0m evaluation \u001b[46m\u001b[30mmethod\u001b[0m inspired by Schutze\t0.012450130794730884\t6.7995325833615965\n",
      "unsupervised method\tin conjunction with \u001b[46m\u001b[30munsupervised\u001b[0m structure finding \u001b[46m\u001b[30mmethods\u001b[0m to derive notions o\t0.012450130794730884\t6.7995325833615965\n",
      "n-gram model\t model, also called \u001b[46m\u001b[30mn-gram\u001b[0m transliteration \u001b[46m\u001b[30mmodel\u001b[0m (ngram TM), is furt\t0.012205925870990699\t7.483303546796265\n",
      "statistical method\tents a phrase-based \u001b[46m\u001b[30mstatistical\u001b[0m machine translation \u001b[46m\u001b[30mmethod\u001b[0m, based on non-conti\t0.01158191937524138\t6.788089682542687\n",
      "statistical method\to apply two generic \u001b[46m\u001b[30mstatistical\u001b[0m learning \u001b[46m\u001b[30mmethods\u001b[0m for combining the i\t0.01158191937524138\t6.788089682542687\n",
      "out-of-domain corpus\t effect of using an \u001b[46m\u001b[30mout-of-domain\u001b[0m bilingual \u001b[46m\u001b[30mcorpus\u001b[0m and the possibility\t0.010959574589072412\t6.601950075585419\n",
      "out-of-domain corpus\tl corpus, we use an \u001b[46m\u001b[30mout-of-domain\u001b[0m bilingual \u001b[46m\u001b[30mcorpus\u001b[0m and, in addition, t\t0.010959574589072412\t6.601950075585419\n",
      "structured data\th (HDAG) Kernel for \u001b[46m\u001b[30mstructured\u001b[0m natural language \u001b[46m\u001b[30mdata\u001b[0m. The HDAG Kernel di\t0.01074468827175972\t5.614810953554988\n",
      "non-parallel corpus\tArabic, and English \u001b[46m\u001b[30mnon-parallel\u001b[0m newspaper \u001b[46m\u001b[30mcorpora\u001b[0m. We evaluate the qu\t0.01012679338167485\t7.809540636209755\n",
      "source language\tthe grammars of the \u001b[46m\u001b[30mSource\u001b[0m and Target \u001b[46m\u001b[30mlanguages\u001b[0m in parallel, in ord\t0.009370355665985625\t6.849652229061629\n",
      "source language\tfrom parse-trees of \u001b[46m\u001b[30msource\u001b[0m and target \u001b[46m\u001b[30mlanguage\u001b[0m sentences. We repor\t0.009370355665985625\t6.849652229061629\n",
      "input document\ttranslations of the \u001b[46m\u001b[30minput\u001b[0m Arabic \u001b[46m\u001b[30mdocuments\u001b[0m can be corrected by\t0.009149782246656628\t4.119064163158749\n",
      "speech processing\tmes have evolved in \u001b[46m\u001b[30mspeech\u001b[0m and text image \u001b[46m\u001b[30mprocessing\u001b[0m work at Xerox PARC \t0.009118109966299292\t5.5619913266596495\n",
      "computer system\tt describes Paul, a \u001b[46m\u001b[30mcomputer\u001b[0m text generation \u001b[46m\u001b[30msystem\u001b[0m designed to create \t0.008971931508993702\t5.11640770762953\n",
      "penn wsj\t24% accuracy on the \u001b[46m\u001b[30mPenn\u001b[0m Treebank \u001b[46m\u001b[30mWSJ\u001b[0m, an error reduction\t0.00786498272611738\t6.81497852370708\n",
      "same context\tassured to have the \u001b[46m\u001b[30msame\u001b[0m beliefs, \u001b[46m\u001b[30mcontexts\u001b[0m, perceptions, backg\t0.007832621987910944\t4.1932074614046675\n",
      "computational system\t for constructing a \u001b[46m\u001b[30mcomputational\u001b[0m phonological \u001b[46m\u001b[30msystem\u001b[0m: speech recognition\t0.007513335827778131\t2.46349562757418\n",
      "different strategy\t integrates several \u001b[46m\u001b[30mdifferent\u001b[0m parsing \u001b[46m\u001b[30mstrategies\u001b[0m, with case-frame in\t0.00748167630252228\t5.088629338260402\n",
      "english sentence\ttic analysis of the \u001b[46m\u001b[30mEnglish\u001b[0m coordinate \u001b[46m\u001b[30msentences\u001b[0m is one of the most \t0.007373487924125521\t5.960320554966973\n",
      "phrase-based model\taper, we describe a \u001b[46m\u001b[30mphrase-based\u001b[0m unigram \u001b[46m\u001b[30mmodel\u001b[0m for statistical mac\t0.006794729696142683\t6.2402123666637905\n",
      "phrase-based model\thod for a localized \u001b[46m\u001b[30mphrase-based\u001b[0m prediction \u001b[46m\u001b[30mmodel\u001b[0m for statistical mac\t0.006794729696142683\t6.2402123666637905\n",
      "phrase-based model\tWe propose a new \u001b[46m\u001b[30mphrase-based\u001b[0m translation \u001b[46m\u001b[30mmodel\u001b[0m and decoding algori\t0.006794729696142683\t6.2402123666637905\n",
      "phrase-based model\tpreviously proposed \u001b[46m\u001b[30mphrase-based\u001b[0m translation \u001b[46m\u001b[30mmodels\u001b[0m. Within our framewo\t0.006794729696142683\t6.2402123666637905\n",
      "source text\tng the meaning of a \u001b[46m\u001b[30msource\u001b[0m language \u001b[46m\u001b[30mtext\u001b[0m rather than finding\t0.006767693467806184\t6.0395509337119595\n",
      "language application\tontains the natural \u001b[46m\u001b[30mlanguage\u001b[0m system and \u001b[46m\u001b[30mapplication\u001b[0m back end.\t0.00520077603956645\t3.976130973042802\n",
      "information system\txtracted field. The \u001b[46m\u001b[30minformation\u001b[0m extraction \u001b[46m\u001b[30msystem\u001b[0m we evaluate is base\t0.003850977702837077\t4.201819768727679\n",
      "language development\tke advantage of the \u001b[46m\u001b[30mlanguage\u001b[0m independent \u001b[46m\u001b[30mdevelopments\u001b[0m of the latter, whil\t0.0016520660276645857\t2.4211305302971113\n",
      "qualitative evaluation\ts of a preliminary, \u001b[46m\u001b[30mqualitative\u001b[0m user \u001b[46m\u001b[30mevaluation\u001b[0m of the system, whic\t0\t7.236032520028273\n",
      "empirical research\tcularly valuable to \u001b[46m\u001b[30mempirical\u001b[0m MT \u001b[46m\u001b[30mresearch\u001b[0m. This piece of work\t0\t5.003622377193603\n"
     ]
    }
   ],
   "source": [
    "for dc, score in sorted(dc_ranks.items(), key=lambda x: x[1], reverse=True):\n",
    "    bridge = dc.get_bridges()[0]\n",
    "    bridge_strength = conceptstats.ngram_pmi(bridge[0].lemma(), bridge[1].lemma(), runpipeline.ngram_model)\\\n",
    "        + math.log10(runpipeline.ngram_model[(bridge[0].lemma(), bridge[1].lemma())])\n",
    "    print(' '.join(dc.normalized_concept()), dc.get_context(), score, bridge_strength, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
